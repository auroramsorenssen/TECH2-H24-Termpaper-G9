{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Termpaper TECH2\n",
    "\n",
    "## NHH Fall 2024 - Group 9: Alexander Solheim, Aurora Malthe-Sørenssen, Balázs Biró\n",
    "### Candidate numbers: 7, xx, xx\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.1 Preliminary data handling and cleaning\n",
    "Since the data is in multiple csv files - concatenate all into a single dataframe and check for data consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify variables for data handling\n",
    "data_path = 'data/'\n",
    "regions = [\"NO2\", \"DE_LU\"]\n",
    "datasets = [\"DayAheadPrices_12.1.D\", \"PhysicalFlows_12.1.G\"]\n",
    "csv_sep = \"\t\"\n",
    "start_year, end_year = 2019, 2023\n",
    "\n",
    "def read_csvs(dataset, start_year, end_year, csv_sep):\n",
    "    \"\"\" Read multiple csv files into a single pandas dataframe \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for month in range(1, 13):\n",
    "            file_path = f\"{data_path}/{dataset}/{year}_{month:02d}_{dataset}.csv\"\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=csv_sep)\n",
    "                data = pd.concat([data, df], ignore_index=True)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P.1.1 - DayAheadPrices\n",
    "- Keep relevant columns\n",
    "- Keep only the two selected regions\n",
    "- Reset indeces for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe for DayAheadPrices and check for consistency\n",
    "dayaheadprices = pd.DataFrame()\n",
    "keep_columns = [\"DateTime\", \"ResolutionCode\", \"MapCode\", \"Price\"] # Relevant columns for the analysis\n",
    "# Keep only the selected MapCodes and relevant columns\n",
    "dayaheadprices = pd.concat([dayaheadprices, read_csvs(datasets[0], start_year, end_year, csv_sep)])[keep_columns]\n",
    "dayaheadprices = dayaheadprices.loc[dayaheadprices[\"MapCode\"].isin(regions)]\n",
    "\n",
    "# Reset indeces\n",
    "dayaheadprices.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# Check for duplicates and missing values\n",
    "print(f\"Duplicate values: {dayaheadprices.duplicated().sum()}\")\n",
    "print(f\"Missing values: {dayaheadprices.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P.1.2 - PhysicalFlows\n",
    "- Keep only the trades between NO2 and DE_LU and vice versa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physicalflows = pd.DataFrame()\n",
    "# Keep only if InMapCode or OutMapCode is NO2 or DE_LU\n",
    "\n",
    "physicalflows = pd.concat([physicalflows, read_csvs(datasets[1], start_year, end_year, csv_sep)])\n",
    "\n",
    "# Keep only trades between the selected regions\n",
    "physicalflows = physicalflows.loc[(physicalflows[\"InMapCode\"].isin(regions)) & (physicalflows[\"OutMapCode\"].isin(regions))]\n",
    "physicalflows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check for duplicates and missing values\n",
    "print(f\"Duplicate values: {physicalflows.duplicated().sum()}\")\n",
    "print(f\"Missing values: {physicalflows.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "### The development of energy prices across the sample period\n",
    "- Visualisation of energy prices in NO2 and DE_LU per hour using a line plot\n",
    "- Showing the official opening time of Nordlink in Dec. 9. 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy from dayaheadprices and filtering to hourly data only\n",
    "dayaheadprices_hourly = dayaheadprices.loc[dayaheadprices[\"ResolutionCode\"] == \"PT60M\"].copy()\n",
    "# Convert DateTime to datetime object\n",
    "dayaheadprices_hourly[\"DateTime\"] = pd.to_datetime(dayaheadprices_hourly[\"DateTime\"])\n",
    "\n",
    "# Plot the hourly prices for the selected regions on two subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "for region, ax in zip(regions, axes):\n",
    "    sns.lineplot(data=dayaheadprices_hourly.loc[dayaheadprices_hourly[\"MapCode\"] == region], x=\"DateTime\", y=\"Price\", ax=ax)\n",
    "    ax.axvline(pd.Timestamp(\"2020-12-09\"), color='red', linestyle='--', label='Nordlink Opening')\n",
    "    ax.set_title(f\"Day-ahead prices for {region}\")\n",
    "    ax.set_ylabel(\"Price [€/MWh]\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "plt.tight_layout()\n",
    "# Save to file\n",
    "plt.savefig(\"figure_task1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### Statistics table for the day ahead price data\n",
    "- Contains the mean, median, standard deviation, min and max for hourly price for each year rounded to two digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a year variable\n",
    "dayaheadprices_hourly[\"Year\"] = dayaheadprices_hourly[\"DateTime\"].dt.year\n",
    "\n",
    "# Calculate the summary statistics for the hourly prices\n",
    "summary = dayaheadprices_hourly.groupby([\"Year\", \"MapCode\"])[\"Price\"].agg([\"mean\", \"median\", \"std\", \"min\", \"max\"]).round(2).reset_index()\n",
    "print(summary)\n",
    "# Save to excel file\n",
    "summary.to_excel(\"table_task2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "### Annual sum of exports and imports of electricity in NO2 on Nordlink\n",
    "- Yearly breakdown\n",
    "- Nordlink only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to datetime object and create a year variable\n",
    "physicalflows[\"DateTime\"] = pd.to_datetime(physicalflows[\"DateTime\"])\n",
    "physicalflows[\"Year\"] = physicalflows[\"DateTime\"].dt.year\n",
    "\n",
    "# Calculate the import and export flows\n",
    "imports, exports = physicalflows[physicalflows[\"InMapCode\"] == \"NO2\"].groupby(\"Year\")[\"FlowValue\"].sum().reset_index(), physicalflows[physicalflows[\"OutMapCode\"] == \"NO2\"].groupby(\"Year\")[\"FlowValue\"].sum().reset_index()\n",
    "imports[\"FlowType\"], exports[\"FlowType\"] = \"Import\", \"Export\"\n",
    "\n",
    "flow_data = pd.concat([imports, exports])\n",
    "\n",
    "# Plot the import and export flows in million MWh\n",
    "sns.barplot(data=flow_data, x=\"Year\", y=\"FlowValue\", hue=\"FlowType\", palette=[\"orange\", \"green\"])\n",
    "plt.title(\"Annual imports and exports of electricity in NO2 with Germany\") \n",
    "plt.ylabel(\"Total electricity flow [in Million MWh]\")\n",
    "plt.yticks(ticks=plt.yticks()[0], labels=[f'{int(tick/1e6)}' for tick in plt.yticks()[0]])\n",
    "plt.savefig(\"figure_task3.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the how much % was the export compared to the import each year\n",
    "percentage, years = (exports[\"FlowValue\"] / imports[\"FlowValue\"] * 100).round(2), imports[\"Year\"]\n",
    "percentage_data = pd.DataFrame({\"Year\": years, \"Percentage\": percentage})\n",
    "sns.lineplot(data=percentage_data, x=\"Year\", y=\"Percentage\", marker=\"o\")\n",
    "plt.title(\"Percentage of exports compared to imports in NO2 with Germany\")\n",
    "plt.ylabel(\"Percentage [%]\")\n",
    "plt.xticks(years)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "### The weekly sum of net exports from NO2 to Germany\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the net export from NO2 to DE_LU each week\n",
    "physicalflows_week = physicalflows.copy()\n",
    "physicalflows_week[\"Week\"] = physicalflows_week[\"DateTime\"].dt.isocalendar().week\n",
    "\n",
    "physicalflows_week[\"NetExport\"] = physicalflows_week.apply(lambda row: row[\"FlowValue\"] if row[\"InMapCode\"] == \"DE_LU\" else -row[\"FlowValue\"], axis=1)\n",
    "\n",
    "weekly_net_exports = physicalflows_week.resample('W', on='DateTime')['NetExport'].sum()\n",
    "\n",
    "# Plot the weekly net exports\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(weekly_net_exports.index, weekly_net_exports.values, marker=\"o\")\n",
    "ax.axhline(0, color='red', linestyle='--', linewidth=1, label='Net Export = 0')\n",
    "ax.set_xlabel('Week')\n",
    "ax.set_ylabel('Net Electricity Flow (MWh)')\n",
    "ax.set_title('Weekly Net Electricity Exports from NO2 to Germany via Nordlink')\n",
    "ax.grid(True)\n",
    "plt.savefig(\"figure_task4.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "### Random stuff\n",
    "- a\n",
    "- b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weekly price difference between germany and no2 and plot the correlation between the weekly price different and the sum of net exports that week\n",
    "dayaheadprices_weekly = dayaheadprices_hourly.copy()\n",
    "\n",
    "prices_filtered = dayaheadprices_weekly.groupby(['DateTime', 'MapCode'])['Price'].mean().reset_index()\n",
    "\n",
    "prices_pivot = prices_filtered.pivot(index='DateTime', columns='MapCode', values='Price')\n",
    "\n",
    "# Calculate the price difference (Germany - NO2).\n",
    "\n",
    "prices_pivot['PriceDifference'] = prices_pivot['DE_LU'] - prices_pivot['NO2']\n",
    "\n",
    "# Resample price difference to weekly average.\n",
    "\n",
    "weekly_price_diff = prices_pivot['PriceDifference'].resample('W').mean()\n",
    "\n",
    "# Combine weekly net exports and weekly average price difference.\n",
    "\n",
    "weekly_data = pd.DataFrame({'NetExports': weekly_net_exports, 'PriceDifference': weekly_price_diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(weekly_data['PriceDifference'], weekly_data['NetExports'], alpha=0.6)\n",
    "# Calculate the correlation coefficient\n",
    "correlation = weekly_data.corr().loc['PriceDifference', 'NetExports']\n",
    "\n",
    "# Plot on a scatter plot\n",
    "ax.set_xlabel('Weekly Average Price Difference (Germany - NO2) (EUR/MWh)')\n",
    "ax.set_ylabel('Weekly Net Exports (MWh)')\n",
    "ax.set_title(f'Weekly Net Exports vs. Price Difference\\nCorrelation: {correlation:.2f}')\n",
    "ax.grid(True)\n",
    "fig.savefig(\"figure_task5.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "termpaper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
